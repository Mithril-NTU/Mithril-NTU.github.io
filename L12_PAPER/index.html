	<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.15" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title> L12_PAPER &middot; Daniel Liu </title>

  
  <link rel="stylesheet" href="http://mithril-ntu.github.io/css/poole.css">
  <link rel="stylesheet" href="http://mithril-ntu.github.io/css/syntax.css">
  <link rel="stylesheet" href="http://mithril-ntu.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Daniel Liu" />
</head>

	<body class="">
		<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="http://mithril-ntu.github.io/"><h1>Daniel Liu</h1></a>
      <p class="lead">
       This is Daniel&#39;s Blog. 
      </p>
    </div>

    <ul class="sidebar-nav">
      <li><a href="/">Home</a> </li>
      
        <li><a href="/HD_LBP/"> HD_LBP </a></li>
      
        <li><a href="/L10_PAPER/"> L10_PAPER </a></li>
      
        <li><a href="/L11_PAPER/"> L11_PAPER </a></li>
      
        <li><a href="/L12_PAPER/"> L12_PAPER </a></li>
      
        <li><a href="/L13_PAPER/"> L13_PAPER </a></li>
      
        <li><a href="/L14_PAPER/"> L14_PAPER </a></li>
      
        <li><a href="/L2_PAPER/"> L2_PAPER </a></li>
      
        <li><a href="/L3_PAPER/"> L3_PAPER </a></li>
      
        <li><a href="/L4_PAPER/"> L4_PAPER </a></li>
      
        <li><a href="/L5_PAPER/"> L5_PAPER </a></li>
      
        <li><a href="/L6_PAPER/"> L6_PAPER </a></li>
      
        <li><a href="/L7_PAPER/"> L7_PAPER </a></li>
      
        <li><a href="/L8_PAPER/"> L8_PAPER </a></li>
      
        <li><a href="/welcome/"> Welcome </a></li>
      
    </ul>

    <p>&copy; 2016. All rights reserved. </p>
  </div>
</div>


		<div class="content container">
			<div class="post">
			 	<h1>L12_PAPER</h1>
			  <span class="post-date">Thu, May 19, 2016</span>
			      

<h3 id="arxiv-16:b22ba9caa617c5be07c9c6fef21aa826">arXiv’16</h3>

<h3 id="text-understanding-from-scratch:b22ba9caa617c5be07c9c6fef21aa826">Text Understanding from Scratch</h3>

<h4 id="introduction:b22ba9caa617c5be07c9c6fef21aa826">Introduction</h4>

<p>This paper proposes a method based on temporal ConvNet which performs surprisingly without any knowledge of words, phrases, sentences and any other syntactic or semantic structures. The authors think that ConvNet operating on characters can learn the hierarchical representations of words, phrases and sentences by itself with a lot of data.</p>

<h4 id="convnet-model-design:b22ba9caa617c5be07c9c6fef21aa826">ConvNet Model Design</h4>

<h5 id="key-modules:b22ba9caa617c5be07c9c6fef21aa826">Key modules</h5>

<p>The key modules used in this paper are similar to what we used in Computer Vision.
The <strong>convolutional</strong> layer is defined as the following equation:
<img src="/L12/Screen%20Shot%202016-05-18%20at%209.01.52%20PM.png" alt="" />
where d is the stride, c=k-d+1 is an offset constant, f(x) is kernel function, g(x) is input function and h(y) is the final output function.
The <strong>max-pooling</strong> layer is defined as below:
<img src="/L12/Screen%20Shot%202016-05-18%20at%209.06.39%20PM.png" alt="" />
The <strong>activation</strong> function is <strong>h(x)=max{0,x}</strong>, which is similar to the ReLu.</p>

<h5 id="character-quantization:b22ba9caa617c5be07c9c6fef21aa826">Character quantization</h5>

<p>The authors first prescribe an alphabet of size m for the input language and then quantize each character using 1-of-m encoding. So, in the end, the input text becomes a l*m matrix, where l means the number of frames and m means the size of each frame. After this quantization, our binary encoding is similar to Braille which is assisting blind reading:
<img src="/L12/Screen%20Shot%202016-05-18%20at%209.18.06%20PM.png" alt="" /></p>

<h5 id="model-design:b22ba9caa617c5be07c9c6fef21aa826">Model Design</h5>

<p>The whole ConvNet framework of this paper is shown below:
<img src="/L12/Screen%20Shot%202016-05-18%20at%209.19.42%20PM.png" alt="" />
which has 6 Conv layers and 3 FC layers.</p>

<h5 id="data-augmentation:b22ba9caa617c5be07c9c6fef21aa826">Data augmentation</h5>

<p>Synonym replacement with an English thesaurus has been used for data augmentation.</p>

<h4 id="experiments:b22ba9caa617c5be07c9c6fef21aa826">Experiments</h4>

<h5 id="performance-on-ontology-classification:b22ba9caa617c5be07c9c6fef21aa826">Performance on Ontology Classification</h5>

<p><img src="/L12/Screen%20Shot%202016-05-18%20at%209.25.01%20PM.png" alt="" />
As we can see, a proper thesaurus augmentation works well for model generalisation.
<img src="/L12/Screen%20Shot%202016-05-18%20at%209.30.32%20PM.png" alt="" />
In the visualization, black (or white) indicates large negative (or positive) values, and gray indicates values near zero. It’s obvious that the ConvNet focuses more on letters than other characters, which means that it has learned something.</p>

<h5 id="performance-on-sentiment-analysis:b22ba9caa617c5be07c9c6fef21aa826">Performance on Sentiment Analysis</h5>

<p><img src="/L12/Screen%20Shot%202016-05-18%20at%209.27.09%20PM.png" alt="" /></p>

<h5 id="performance-on-topic-classification:b22ba9caa617c5be07c9c6fef21aa826">Performance on Topic Classification</h5>

<p><img src="/L12/Screen%20Shot%202016-05-18%20at%209.27.42%20PM.png" alt="" /></p>

<h5 id="performance-on-news-categorization-in-english:b22ba9caa617c5be07c9c6fef21aa826">Performance on News Categorization in English</h5>

<p><img src="/L12/Screen%20Shot%202016-05-18%20at%209.28.07%20PM.png" alt="" />
The overfitting occurred in this result reveals that to achieve good text understanding results ConvNets require a large corpus.</p>

<h5 id="performance-on-news-categorization-in-chinese:b22ba9caa617c5be07c9c6fef21aa826">Performance on News Categorization in Chinese</h5>

<p><img src="/L12/Screen%20Shot%202016-05-18%20at%209.28.18%20PM.png" alt="" />
Both in Chinese and English the method performs well and thus prove its generalisation.</p>

			</div>

			
		</div>

  </body>
</html>
