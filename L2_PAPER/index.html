	<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.15" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title> L2_PAPER &middot; Daniel Liu </title>

  
  <link rel="stylesheet" href="http://mithril-ntu.github.io/css/poole.css">
  <link rel="stylesheet" href="http://mithril-ntu.github.io/css/syntax.css">
  <link rel="stylesheet" href="http://mithril-ntu.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Daniel Liu" />
</head>

	<body class="">
		<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="http://mithril-ntu.github.io/"><h1>Daniel Liu</h1></a>
      <p class="lead">
       This is Daniel&#39;s Blog. 
      </p>
    </div>

    <ul class="sidebar-nav">
      <li><a href="/">Home</a> </li>
      
        <li><a href="/HD_LBP/"> HD_LBP </a></li>
      
        <li><a href="/L2_PAPER/"> L2_PAPER </a></li>
      
        <li><a href="/L3_PAPER/"> L3_PAPER </a></li>
      
        <li><a href="/L4_PAPER/"> L4_PAPER </a></li>
      
        <li><a href="/L5_PAPER/"> L5_PAPER </a></li>
      
        <li><a href="/L6_PAPER/"> L6_PAPER </a></li>
      
        <li><a href="/welcome/"> Welcome </a></li>
      
    </ul>

    <p>&copy; 2016. All rights reserved. </p>
  </div>
</div>


		<div class="content container">
			<div class="post">
			 	<h1>L2_PAPER</h1>
			  <span class="post-date">Mon, Mar 14, 2016</span>
			      

<h3 id="cvpr-10:87f4392be42726eab66708aaabb6a62d">CVPR‘10</h3>

<h3 id="aggregating-local-descriptors-into-a-compact-image-representation:87f4392be42726eab66708aaabb6a62d">Aggregating local descriptors into a compact image representation</h3>

<h4 id="abstract:87f4392be42726eab66708aaabb6a62d">Abstract</h4>

<h5 id="problem:87f4392be42726eab66708aaabb6a62d">Problem:</h5>

<p>To find an image search algorithm for large dataset with high accuracy and efficiency and low memory cost</p>

<h5 id="solution:87f4392be42726eab66708aaabb6a62d">Solution:</h5>

<ol>
<li>Aggregating local image descriptors into a vector with limited dimension</li>
<li>jointly reduce features’ dimension and index them</li>
</ol>

<h4 id="introduction:87f4392be42726eab66708aaabb6a62d">Introduction</h4>

<p>Today’s approaches are hard to fulfil 3 constraints: the search accuracy, its efficiency and the memory usage. To overcome this, the authors propose a new approach called “VLAD(Vector of Locally Aggregated Descriptors)”.
It proposes an image representation that provides high search accuracy with reasonable vector dimensionality. Then it jointly optimising the trade-off between the dimensionality reduction and the indexation algorithm.</p>

<h4 id="paper-structure:87f4392be42726eab66708aaabb6a62d">Paper structure</h4>

<pre><code>2.Image vector representation
2.1.Bag of features
2.2.Fisher kernel
2.3.VLAD

3.From vectors to codes
3.1.Approximate nearest neighbour
3.2.Indexation-aware dimensionality reduction

4.Experiments
4.1.Evaluation datasets and local descriptor
4.2.Image vector representations
4.3.Reduction and indexation
4.4.Compare with the state of the art
4.5.Large scale experiments
</code></pre>

<h4 id="2-image-vector-representation:87f4392be42726eab66708aaabb6a62d">2. Image vector representation</h4>

<h5 id="2-1-bag-of-features:87f4392be42726eab66708aaabb6a62d">2.1. Bag of features</h5>

<p>Extract local features from images —&gt; Group these features into k “visual words”(k-means clustering) —&gt; Represent an image by a weighted and normalised histograms</p>

<h5 id="2-2-fisher-kernel:87f4392be42726eab66708aaabb6a62d">2.2 Fisher kernel</h5>

<p>Learn a parametric generative model from training data -&gt; Describe a image with the gradient in parameter space which means how the learnt model should be modified to better fit the observed data</p>

<h5 id="2-3-vlad:87f4392be42726eab66708aaabb6a62d">2.3. VLAD</h5>

<p>1) Use SIFT descriptors &amp; Learn k “visual words” ;
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%204.36.18%20PM.png" alt="" />
2) Compute VLAD；
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%204.36.36%20PM.png" alt="" />
3) v is subsequently L2 -normalized；
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%204.39.34%20PM.png" alt="" />
The whole computation is like following:
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%204.40.27%20PM.png" alt="" /></p>

<h4 id="3-from-vectors-to-codes:87f4392be42726eab66708aaabb6a62d">3. From vectors to codes</h4>

<p>This problem is divided into 2 steps: 1) a projections that reduces the dimensionality of the vector and 2) a quantisation used to index the resulting vectors.</p>

<h5 id="3-1-approximate-nearest-neighbour:87f4392be42726eab66708aaabb6a62d">3.1. Approximate nearest neighbour</h5>

<p>ANN is an approach that embeds a vector into a binary space with  excellent accuracy and efficient memory usage. And it provides explicit approximation of the indexed vectors.The author uses the asymmetric distance computation(ADC) variant of this approach.
To find the α nearest neighbours NN_α(x) of x, we just need compute:
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.32.29%20PM.png" alt="" />
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.32.44%20PM.png" alt="" />
To embed the vector x into a binary space, we first spill it into (x^1, … , x^m) of equal length D/m. Then a product of quantiser is :
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.32.37%20PM.png" alt="" />
The approximation between the original vector y and the quantiser is:
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.32.53%20PM.png" alt="" /></p>

<h5 id="3-2-indexation-aware-dimensionality-reduction:87f4392be42726eab66708aaabb6a62d">3.2. Indexation-aware dimensionality reduction</h5>

<p>The author use PCA for dimensionality reduction. Mapping a vector x ∈ R^D to x’=Mx ∈ R^D’ will lead to information loss:
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.46.01%20PM.png" alt="" />
With quantisation, this becomes:
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.47.14%20PM.png" alt="" />
IF D’ is large, then ε_p(x) is limited and ε_q(x) is large. There is a trade-off on the number of D’.</p>

<p>May here can use some optimisation algorithms.</p>

<p>In addition, because PCA, the variance of the different components of x’ is not balanced. So the author performs an orthogonal transformation after PCA: X’’ = QX’ = QMX’.
Q is chose in the form of a Householder matrix:
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.54.12%20PM.png" alt="" />
or is chose as a random orthogonal matrix.</p>

<h4 id="4-experiments:87f4392be42726eab66708aaabb6a62d">4.Experiments</h4>

<h5 id="4-1-evaluation-datasets-and-local-descriptor:87f4392be42726eab66708aaabb6a62d">4.1.Evaluation datasets and local descriptor</h5>

<p>3 datasets: 1) INRIA Holidays dataset; 2) UKB dataset; 3) 10M images collected from Flickr</p>

<h5 id="4-2-image-vector-representations:87f4392be42726eab66708aaabb6a62d">4.2.Image vector representations</h5>

<p><img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%207.02.31%20PM.png" alt="" /></p>

<h5 id="4-3-reduction-and-indexation:87f4392be42726eab66708aaabb6a62d">4.3.Reduction and indexation</h5>

<p>1) Balancing the variance
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%207.03.35%20PM.png" alt="" />
2) Choice of the projection subspace dimension
<img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%207.03.41%20PM.png" alt="" /></p>

<h5 id="4-4-compare-with-the-state-of-the-art:87f4392be42726eab66708aaabb6a62d">4.4.Compare with the state of the art</h5>

<p><img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%207.04.16%20PM.png" alt="" />
For the same memory usage, this paper’s method outperforms others!</p>

<h5 id="4-5-large-scale-experiments:87f4392be42726eab66708aaabb6a62d">4.5.Large scale experiments</h5>

<p><img src="/AMMAI_L2/Screen%20Shot%202016-03-14%20at%207.07.03%20PM.png" alt="" /></p>

			</div>

			
		</div>

  </body>
</html>
