<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Daniel Liu</title>
    <link>http://Mithril-NTU.github.io/</link>
    <description>Recent content on Daniel Liu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Mar 2016 00:56:44 +0800</lastBuildDate>
    <atom:link href="http://Mithril-NTU.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>L3_PAPER</title>
      <link>http://mithril-ntu.github.io/L3_PAPER/</link>
      <pubDate>Wed, 16 Mar 2016 00:56:44 +0800</pubDate>
      
      <guid>http://mithril-ntu.github.io/L3_PAPER/</guid>
      <description>

&lt;h3 id=&#34;cvpr-11:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;CVPR‘11&lt;/h3&gt;

&lt;h3 id=&#34;iterative-quantization-a-procrustean-approach-to-learning-binary-codes:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;Iterative Quantization: A Procrustean Approach to Learning Binary Codes&lt;/h3&gt;

&lt;h4 id=&#34;abstract:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;Abstract&lt;/h4&gt;

&lt;h5 id=&#34;problem:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;Problem:&lt;/h5&gt;

&lt;p&gt;Learn similarity-preserving binary codes for efficient retrieval  in large scale image collections&lt;/p&gt;

&lt;h5 id=&#34;solution:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;Solution:&lt;/h5&gt;

&lt;p&gt;An alternating minimization scheme(ITQ, Iterative Quantization): Finding a a rotation of zero-centered data so as to minimize the quantization error of mapping this data to the vertices of a zero-centered binary hypercube
ITQ can be used with unsupervised or supervised data embeddings&lt;/p&gt;

&lt;h4 id=&#34;introduction:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;Introduction&lt;/h4&gt;

&lt;p&gt;Encode high-dimensional image descriptor as compact binary strings. This codes should have 3 properties: 1) short enough for storing large datasets, 2) map similar images to binary codes with a low Hamming distance, 3) encode new images efficiently
The author’s approach is like following:
PCA -&amp;gt; Apply a random orthogonal transformation(counteract the variance of different PCA directions) —&amp;gt; ITQ for refining the initial orthogonal transformation to minimize quantization error&lt;/p&gt;

&lt;h4 id=&#34;paper-structure:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;Paper structure&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;2. Unsupervised Code Learning 
2.1. Dimensionality Reduction
2.2. Binary Quantization

3. Evaluation of Unsupervised Code Learning 
3.1. Datasets
3.2. Protocols and Baseline Methods
3.3. Results on CIFAR Dataset
3.4. Results on 580000 Tiny Images

4. Leveraging Label Information

5. Discussion
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-unsupervised-code-learning:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;2. Unsupervised Code Learning&lt;/h4&gt;

&lt;p&gt;Procedure:
1) Apply linear dimensionality reduction to the data(PCA)
2) Perform binary quantization&lt;/p&gt;

&lt;h5 id=&#34;2-1-dimensionality-reduction:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;2.1. Dimensionality Reduction&lt;/h5&gt;

&lt;p&gt;To maximize the variance approximately, we get the following objective function:
&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-15%20at%2011.53.58%20PM.png&#34; alt=&#34;&#34; /&gt;
This is the same as PCA, so we get W by taking the top c eigenvectors of the data covariance matrix  X^TX&lt;/p&gt;

&lt;h5 id=&#34;2-2-binary-quantization:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;2.2. Binary Quantization&lt;/h5&gt;

&lt;p&gt;To minimize the quantization loss, we get:
&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.09.58%20AM.png&#34; alt=&#34;&#34; /&gt;
where ||.||_F is the Frobenius norm and R is some orthogonal c*c matrix.
The author initializes the R as a random orthogonal matrix. Then     adopt the ITQ procedure:
1) Fix R and update B:
Expanding the formulation above, we have
&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.24.50%20AM.png&#34; alt=&#34;&#34; /&gt;
Minimizing this is equivalent to maximize:
&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.26.09%20AM.png&#34; alt=&#34;&#34; /&gt;
2) Fix B and update R:
a) Compute the SVD of the c*c matrix B^TV as SΩS’^T
b) Let R = S’S^T
&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.29.23%20AM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;3-evaluation-of-unsupervised-code-learning:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;3. Evaluation of Unsupervised Code Learning&lt;/h4&gt;

&lt;h5 id=&#34;3-1-datasets:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;3.1. Datasets&lt;/h5&gt;

&lt;p&gt;1) CIFAR dataset; 2)580000 Tiny images&lt;/p&gt;

&lt;h5 id=&#34;3-2-protocols-and-baseline-methods:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;3.2. Protocols and Baseline Methods&lt;/h5&gt;

&lt;p&gt;Protocols:
1) To evaluate performance of nearest neighbor search using Euclidean neighbors as ground truth
2) To evaluate the semantic consistency of codes produced by different methods by using class labels as ground truth.
Baseline methods:
1) LSH; 2) PCA-Direct; 3) PCA-RR; 4) SH; 5) SKLSH; 6) PCA-Nonorth&lt;/p&gt;

&lt;h5 id=&#34;3-3-results-on-cifar-dataset:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;3.3. Results on CIFAR Dataset&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.42.06%20AM.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.36.03%20AM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;3-4-results-on-580000-tiny-images:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;3.4. Results on 580000 Tiny Images&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.41.03%20AM.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.41.08%20AM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;4-leveraging-label-information:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;4. Leveraging Label Information&lt;/h4&gt;

&lt;p&gt;This section shows how to refine the binary codes in a supervised setting using Canonical Correlation Analysis(CCA).
The goal of CCA is to find projection directions w_k and u_k for feature and label vectors to maximize the correlation between the projected data X*w_k and Y*u_k:
&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.48.41%20AM.png&#34; alt=&#34;&#34; /&gt;
The author compares his method with a semi-supervised approach(SSH):
&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.50.50%20AM.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;AMMAI_L3Screen%20Shot%202016-03-16%20at%2012.51.45%20AM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;5-discussion:f809bb8f2a579f5c8d55fa3650d344a6&#34;&gt;5. Discussion&lt;/h4&gt;

&lt;p&gt;Contributions of this paper:
1) Show that the performance of PCA-based binary coding schemes can be greatly improved by simply rotating the projected data.
2) Demonstrate an iterative quantization method for refining this rotation that is very natural and effective.
Limitation:
Use one bit per projected data dimension.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>L2_PAPER</title>
      <link>http://mithril-ntu.github.io/L2_PAPER/</link>
      <pubDate>Mon, 14 Mar 2016 19:23:42 +0800</pubDate>
      
      <guid>http://mithril-ntu.github.io/L2_PAPER/</guid>
      <description>

&lt;h3 id=&#34;cvpr-10:87f4392be42726eab66708aaabb6a62d&#34;&gt;CVPR‘10&lt;/h3&gt;

&lt;h3 id=&#34;aggregating-local-descriptors-into-a-compact-image-representation:87f4392be42726eab66708aaabb6a62d&#34;&gt;Aggregating local descriptors into a compact image representation&lt;/h3&gt;

&lt;h4 id=&#34;abstract:87f4392be42726eab66708aaabb6a62d&#34;&gt;Abstract&lt;/h4&gt;

&lt;h5 id=&#34;problem:87f4392be42726eab66708aaabb6a62d&#34;&gt;Problem:&lt;/h5&gt;

&lt;p&gt;To find an image search algorithm for large dataset with high accuracy and efficiency and low memory cost&lt;/p&gt;

&lt;h5 id=&#34;solution:87f4392be42726eab66708aaabb6a62d&#34;&gt;Solution:&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;Aggregating local image descriptors into a vector with limited dimension&lt;/li&gt;
&lt;li&gt;jointly reduce features’ dimension and index them&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;introduction:87f4392be42726eab66708aaabb6a62d&#34;&gt;Introduction&lt;/h4&gt;

&lt;p&gt;Today’s approaches are hard to fulfil 3 constraints: the search accuracy, its efficiency and the memory usage. To overcome this, the authors propose a new approach called “VLAD(Vector of Locally Aggregated Descriptors)”.
It proposes an image representation that provides high search accuracy with reasonable vector dimensionality. Then it jointly optimising the trade-off between the dimensionality reduction and the indexation algorithm.&lt;/p&gt;

&lt;h4 id=&#34;paper-structure:87f4392be42726eab66708aaabb6a62d&#34;&gt;Paper structure&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;2.Image vector representation
2.1.Bag of features
2.2.Fisher kernel
2.3.VLAD

3.From vectors to codes
3.1.Approximate nearest neighbour
3.2.Indexation-aware dimensionality reduction

4.Experiments
4.1.Evaluation datasets and local descriptor
4.2.Image vector representations
4.3.Reduction and indexation
4.4.Compare with the state of the art
4.5.Large scale experiments
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-image-vector-representation:87f4392be42726eab66708aaabb6a62d&#34;&gt;2. Image vector representation&lt;/h4&gt;

&lt;h5 id=&#34;2-1-bag-of-features:87f4392be42726eab66708aaabb6a62d&#34;&gt;2.1. Bag of features&lt;/h5&gt;

&lt;p&gt;Extract local features from images —&amp;gt; Group these features into k “visual words”(k-means clustering) —&amp;gt; Represent an image by a weighted and normalised histograms&lt;/p&gt;

&lt;h5 id=&#34;2-2-fisher-kernel:87f4392be42726eab66708aaabb6a62d&#34;&gt;2.2 Fisher kernel&lt;/h5&gt;

&lt;p&gt;Learn a parametric generative model from training data -&amp;gt; Describe a image with the gradient in parameter space which means how the learnt model should be modified to better fit the observed data&lt;/p&gt;

&lt;h5 id=&#34;2-3-vlad:87f4392be42726eab66708aaabb6a62d&#34;&gt;2.3. VLAD&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;Use SIFT descriptors &amp;amp; Learn k “visual words” ;
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%204.36.18%20PM.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;Compute VLAD；
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%204.36.36%20PM.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;v is subsequently L2 -normalized；
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%204.39.34%20PM.png&#34; alt=&#34;&#34; /&gt;
The whole computation is like following:
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%204.40.27%20PM.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;3-from-vectors-to-codes:87f4392be42726eab66708aaabb6a62d&#34;&gt;3. From vectors to codes&lt;/h4&gt;

&lt;p&gt;This problem is divided into 2 steps: 1) a projections that reduces the dimensionality of the vector and 2) a quantisation used to index the resulting vectors.&lt;/p&gt;

&lt;h5 id=&#34;3-1-approximate-nearest-neighbour:87f4392be42726eab66708aaabb6a62d&#34;&gt;3.1. Approximate nearest neighbour&lt;/h5&gt;

&lt;p&gt;ANN is an approach that embeds a vector into a binary space with  excellent accuracy and efficient memory usage. And it provides explicit approximation of the indexed vectors.The author uses the asymmetric distance computation(ADC) variant of this approach.
To find the α nearest neighbours NN_α(x) of x, we just need compute:
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.32.29%20PM.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.32.44%20PM.png&#34; alt=&#34;&#34; /&gt;
To embed the vector x into a binary space, we first spill it into (x^1, … , x^m) of equal length D/m. Then a product of quantiser is :
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.32.37%20PM.png&#34; alt=&#34;&#34; /&gt;
The approximation between the original vector y and the quantiser is:
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.32.53%20PM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;3-2-indexation-aware-dimensionality-reduction:87f4392be42726eab66708aaabb6a62d&#34;&gt;3.2. Indexation-aware dimensionality reduction&lt;/h5&gt;

&lt;p&gt;The author use PCA for dimensionality reduction. Mapping a vector x ∈ R^D to x’=Mx ∈ R^D’ will lead to information loss:
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.46.01%20PM.png&#34; alt=&#34;&#34; /&gt;
With quantisation, this becomes:
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.47.14%20PM.png&#34; alt=&#34;&#34; /&gt;
IF D’ is large, then ε_p(x) is limited and ε_q(x) is large. There is a trade-off on the number of D’.&lt;/p&gt;

&lt;p&gt;May here can use some optimisation algorithms.&lt;/p&gt;

&lt;p&gt;In addition, because PCA, the variance of the different components of x’ is not balanced. So the author performs an orthogonal transformation after PCA: X’’ = QX’ = QMX’.
Q is chose in the form of a Householder matrix:
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%206.54.12%20PM.png&#34; alt=&#34;&#34; /&gt;
or is chose as a random orthogonal matrix.&lt;/p&gt;

&lt;h4 id=&#34;4-experiments:87f4392be42726eab66708aaabb6a62d&#34;&gt;4.Experiments&lt;/h4&gt;

&lt;h5 id=&#34;4-1-evaluation-datasets-and-local-descriptor:87f4392be42726eab66708aaabb6a62d&#34;&gt;4.1.Evaluation datasets and local descriptor&lt;/h5&gt;

&lt;p&gt;3 datasets: 1) INRIA Holidays dataset; 2) UKB dataset; 3) 10M images collected from Flickr&lt;/p&gt;

&lt;h5 id=&#34;4-2-image-vector-representations:87f4392be42726eab66708aaabb6a62d&#34;&gt;4.2.Image vector representations&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%207.02.31%20PM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;4-3-reduction-and-indexation:87f4392be42726eab66708aaabb6a62d&#34;&gt;4.3.Reduction and indexation&lt;/h5&gt;

&lt;p&gt;1) Balancing the variance
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%207.03.35%20PM.png&#34; alt=&#34;&#34; /&gt;
2) Choice of the projection subspace dimension
&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%207.03.41%20PM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;4-4-compare-with-the-state-of-the-art:87f4392be42726eab66708aaabb6a62d&#34;&gt;4.4.Compare with the state of the art&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%207.04.16%20PM.png&#34; alt=&#34;&#34; /&gt;
For the same memory usage, this paper’s method outperforms others!&lt;/p&gt;

&lt;h5 id=&#34;4-5-large-scale-experiments:87f4392be42726eab66708aaabb6a62d&#34;&gt;4.5.Large scale experiments&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://Mithril-NTU.github.io/AMMAI_L2/Screen%20Shot%202016-03-14%20at%207.07.03%20PM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Welcome</title>
      <link>http://mithril-ntu.github.io/welcome/</link>
      <pubDate>Sat, 12 Mar 2016 02:29:56 +0800</pubDate>
      
      <guid>http://mithril-ntu.github.io/welcome/</guid>
      <description>

&lt;h3 id=&#34;first-blog:2cc7dc244eed4480e8b46c91e911e96b&#34;&gt;First Blog&lt;/h3&gt;

&lt;p&gt;Hello Everyone!&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://Mithril-NTU.github.io/media/tn.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;example&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;

</description>
    </item>
    
  </channel>
</rss>